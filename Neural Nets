#####################
## Neuronales Netz ##
#####################

import keras
from keras.layers import Dense
from keras.models import Sequential
from keras.callbacks import EarlyStopping
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from sklearn.metrics import confusion_matrix, classification_report


y_n2 = df1['Class']
X_n2 = df_not_class_scaled

X10_train, X10_test, y10_train, y10_test = train_test_split(X_n2, y_n2, test_size = 0.4, random_state = 21)

model10 = Sequential()
cols = X10_train.shape[1]

# first layer
model10.add(Dense(20, activation = "relu", input_shape = (cols, )))
# second layer
model10.add(Dense(20, activation = "relu"))
# output layer
model10.add(Dense(1))

model10.compile(optimizer = 'adam', loss = 'mean_squared_error')

early_stopping_monitor = EarlyStopping(patience = 20)

model10.fit(X10_test, y10_test, epochs = 100,
          callbacks = [early_stopping_monitor])


pred10 = model10.predict(X10_test)

from keras.models import load_model

#model10.save(r'C:\Users\Nico\Documents\TechLabs.m10')


model10.save('my_model_10')
model10 = load_model('my_model_10')


# wieder zu bin채ren Variabblen zur체ck
list_pred_10 = []

for a in pred10:
    if a < 0.5:
        list_pred_10.append(0)
    else:
        list_pred_10.append(1)
        
print(list_pred_10)
list_pred_10a = pd.DataFrame(list_pred_10)

y10_test = pd.DataFrame(y10_test)

y10_test["pred"] =  list_pred_10
y10_test["abs_loss"] = y10_test["Class"] - y10_test["pred"] 
y10_test["abs_loss"] = abs(y10_test["abs_loss"])

np.mean(y10_test["abs_loss"])
# 0.0003247807729782397

# besser:
list_pred_10 = []

for a in y10_pred:
    if a < 0.5:
        list_pred_10.append(0)
    else:
        list_pred_10.append(1)

cm10 = confusion_matrix(y10_pred, list_pred_10)
print(cm10)
scores(cm10)

# geht noch besser!

## nun mit df2
df2 = df1[["Time", "V3", "V4", "V7","V9","V10","V11","V12","V14","V16","V17","V18", "V21","V26","V27"]]


y_n3 = df1['Class']
X_n3 = df2

X11_train, X11_test, y11_train, y11_test = train_test_split(X_n3, y_n3, test_size = 0.4, random_state = 21)

model11 = Sequential()
cols = X11_train.shape[1]

# first layer
model11.add(Dense(20, activation = "relu", input_shape = (cols, )))
# second layer
model11.add(Dense(20, activation = "relu"))
# third layer
model11.add(Dense(20, activation = "relu"))
# output layer
model11.add(Dense(1))


model11.compile(optimizer = 'adam', loss = 'mean_squared_error')

early_stopping_monitor = EarlyStopping(patience = 20)

model11.fit(X11_test, y11_test, epochs = 100,
          callbacks = [early_stopping_monitor])


pred11 = model11.predict(X11_test)


from keras.models import load_model

#model11.save(r'C:\Users\Nico\Documents\TechLabs.m11')

model11.save()

model11.save('my_model_11')
model11 = load_model('my_model_11')

# wieder zu bin채ren Variabblen zur체ck
list_pred_11 = []

for a in pred11:
    if a < 0.5:
        list_pred_11.append(0)
    else:
        list_pred_11.append(1)
        
print(list_pred_11)
list_pred_11a = pd.DataFrame(list_pred_11)

y11_test = pd.DataFrame(y11_test)

y11_test["pred"] =  list_pred_11
y11_test["abs_loss"] = y11_test["Class"] - y11_test["pred"] 
y11_test["abs_loss"] = abs(y11_test["abs_loss"])

np.mean(y11_test["abs_loss"])
# 0.0016677931585369066
# deutlich mehr als bei der standardisiertem Datensatz

cm11 = confusion_matrix(y11_pred, list_pred_11)
print(cm11)
scores(cm11)

